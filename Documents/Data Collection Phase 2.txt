Fixed Rules (Re-confirmed)

Execution mode: Sequential

Posts per creator: 100â€“150

Comments per post: 50

Data source: Visible Instagram UI only

No ML, no aggregation, no inference in this phase

ğŸªœ STEP-BY-STEP LOGIC (What Playwright Does)
ğŸ”¹ STEP 1: Load Phase 1 JSON

Playwright starts by loading the post index JSON created in Phase 1.

From it, we read:

creator_username

niche

posts_index[] â†’ list of post URLs

This list becomes the authoritative input.

ğŸ“Œ If Phase 1 JSON changes â†’ Phase 2 output changes
ğŸ“Œ This is reproducible and auditable

ğŸ”¹ STEP 2: Initialize Sequential Loop

Internally, we track:

current_post_index

total_posts_to_scrape

success_count

failure_count

Example (conceptual):

Scraping post 1 / 120
Scraping post 2 / 120
...


This is great for logs and demo visibility.

ğŸ”¹ STEP 3: Open ONE Post

For the current post:

Navigate to:

https://www.instagram.com/p/<post_id>/


Wait until:

Post container loads

Caption area is visible

Metrics section is visible

â³ Waits are intentional to avoid DOM race conditions.

ğŸ”¹ STEP 4: Extract POST METADATA

From visible UI, extract:

Identity

post_id

reel_url

post_type (reel)

Time

posted_at (from <time datetime="">)

scraped_at (current system time)

ğŸ“Œ These two timestamps are very important academically.

ğŸ”¹ STEP 5: Extract CAPTION & HASHTAGS

Playwright reads:

Full caption text

Extracts hashtags from caption

Counts hashtags

Stored as:

caption

hashtags[]

hashtag_count

âŒ No NLP
âŒ No topic detection
âœ” Raw text only

ğŸ”¹ STEP 6: Extract METRICS (Visible Only)

From the UI:

views

likes

comments_count

shares (only if visible)

Rules:

Numbers may be in K / M

Stored as-is or normalized later (your choice, but I recommend normalize in cleaning phase)

âŒ No engagement rate here

ğŸ”¹ STEP 7: Open Comments Section

Playwright:

Clicks â€œView all commentsâ€

Waits for comments to load

Scrolls comments area slowly

ğŸ”¹ STEP 8: Collect EXACTLY 50 COMMENTS

Sequential comment logic:

Start from top

After each scroll:

Read newly visible comments

Append to list

Stop immediately when:

comments_collected == 50


For each comment, store:

comment_order

comment_text

scraped_at

ğŸ“Œ You explicitly do not claim completeness
ğŸ“Œ This is a sample, and that is documented

ğŸ”¹ STEP 9: Save POST DATA IMMEDIATELY

After finishing one post, Playwright:

Appends post data to in-memory structure

OR writes incrementally to disk

This is critical:

If scraping stops at post 63, you still have data for 62 posts.

Sequential mode shines here.

ğŸ”¹ STEP 10: Move to NEXT Post

Only after:

Post metrics âœ…

Caption âœ…

50 comments âœ…

Data saved âœ…

â€¦Playwright moves to the next URL.

No overlap. No concurrency.

ğŸ”¹ STEP 11: Handle Failures (Gracefully)

If a post fails to load or comments donâ€™t appear:

Mark post as:

status: "failed"
reason: "comments_not_visible"


Continue to next post

Log failure separately

This is honest and professional.

ğŸ”¹ STEP 12: Final Phase 2 JSON Output

At the end, you produce one JSON per creator:

post_content_<creator>_<YYYY-MM-DD>.json


Includes:

posts[]

summary

failure_log[]

This is your raw dataset